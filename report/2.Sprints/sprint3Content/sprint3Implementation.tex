\section{Implementation} \label{SEC:Sprint3Implementation}
As described in \autoref{SEC:Sprint3Issues} the two issues assigned to the group for this sprint were primarily on the servers of the project.
In the following the two issues and their related implementation will be elaborated upon.

\subsection{MySQL migration}
Based upon \href{https://github.com/aau-giraf/wiki/issues/35}{issue \texttt{\#}35} the original database should be migrated from the existing servers to the new.
Since the new servers utilize the Docker Swarm, the first task in solving the issue is to create a new service in the Swarm.
This is done within the \text{docker-compose.yml} file.
On \autoref{DatabaseService} a part of the file is shown, displaying the definition of the DB service and all its configurations.
The service uses the same version of MySQL as the old servers did, version $5.7.11$, in order to avoid any braking changes that the different versions of MySQL could have implemented in newer versions.
The services uses an NFS file share hosted by ITS to store the database files.
This means that the service can be started in any of the servers and still have the same data available.

\begin{lstlisting}[caption={Docker database service},captionpos=b,label=DatabaseService,escapechar=\%]
%\dots%
DB:                          # The DB service will be changed to use the production database later once it has been migrated. The httpd image is only for testing.
    image: mysql:5.7.11
    command: --default-authentication-plugin=mysql_native_password
    volumes:                 # Mounts the mysql files from the NFS to the container
        - /swarm-nfs/mysql/:/var/lib/mysql/
    environment:             # MySQL root password
        MYSQL_ROOT_PASSWORD: <password>
    networks:                # Attaches the network
        - backend
    deploy:                  # Deploy options
        restart_policy:      # On failure restart the service
            condition: on-failure
%\dots%
\end{lstlisting}

The primary issue with the old servers was that the database was accessible from the public internet.
In order to mitigate this issue the new Docker Swarm has two different networks; one for the frontend and one for the backend.
The backend network is attached to both the API and the database services which means that in order to reach the database from public internet all traffic must pass through the API.
Furthermore, Docker allows us to specify what action should be taken once the service experiences a failure and are unable to recover -- in this case the service should simply reboot.

Once the service had been started, the only thing left was to create a dump from the existing MySQL server.
For this the tool \lstinline$mysqldump$ was used to dump the database to a file.
The newly created \lstinline$.sql$ file can now be moved to the new servers and imported into the database with the \lstinline$mysql -u root -p giraf-release < data.sql$

Once the data has been imported into the database it is ready to serve the data for the project.

\subsection{API migration}
In order to migrate the API from the existing servers to the new servers, the Docker Image used to serve the old Docker containers should be updated.
The old semester had created a Dockerfile that used the Dotnet Core SDK for hosting the project, which meant that the entire Docker Image would take up $2240 Mb$ for storage.
Since the new servers supplied by ITS have very small disk-storages, using the old image-files would quickly fill up the storage, rendering the servers unusable.
This problem could however by fixed by telling the Dotnet Core SDK to build the project for production and then use the Dotnet Core runtime to serve the API.
These changes have resulted in a new Dockerfile which can be seen on \autoref{APIDockerfile}.

By adding this extra step the total size of the Docker Image was reduced dramatically, as can be seen on \autoref{DockerImageSize}.
This reduction in size allows each server to more quickly pull a new image from a Docker-repository, and also results in the stored images to fill up much less disk space on the servers.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
Old & 2240 Mb \\ \hline
New &  339 Mb  \\ \hline
\end{tabular}
\caption{Difference in Docker Image size}
\label{DockerImageSize}
\end{table}


\begin{lstlisting}[caption={API Dockerfile},captionpos=b,label=APIDockerfile,escapechar=\%]
# Using microsoft dotnet software development kit as
# the build envionment.
FROM mcr.microsoft.com/dotnet/core/sdk:2.2 AS build-env
WORKDIR /app

# Copy csproj and restore as distinct layers
COPY GirafRest/*.csproj ./
RUN dotnet restore

# Copy everything else and build
COPY ./GirafRest/ ./

# Build the app for production
RUN dotnet publish -c Release -o out

#------------------------------------------#

# Using microsoft aps net core 2.2 as hosting envionment
FROM mcr.microsoft.com/dotnet/core/aspnet:2.2 AS runtime-env
WORKDIR /srv

# COPY from build envionment into local container.
COPY --from=build-env /app/out .

# Remove the appsettings files from the container
# so no passwords are pushed to docker hub
RUN rm appsettings*

# Expose the port intented for communications
EXPOSE 5000

# Start running the app.
ENTRYPOINT ["dotnet", "GirafRest.dll", "--list"]
\end{lstlisting}

Once the API Docker Image had been updated to not include passwords, the Docker Swarm could be updated to use the new and enhanced Docker Image.
On \autoref{APIService} a section of the \lstinline$docker-compose.yml$ file can be seen.
The service uses the NFS file share to store pictograms and to store the confidential \lstinline$appsettings.json$ file which is then mounted inside the containers.

The API services are all connected to both the frontend and backend network in order for the API to communicate to the database, and for the API to communicate to the internet via a reverse proxy.
Each version of the API has three replicas of each service, in order to void downtime on the entire service in case of a failure in a container.

With Docker Swarm comes the ability to make ongoing health checks on the containers.
This is used in the API to check whether the API is still responding to a request or not.
If a container does not respond three times in a row it will be terminated and a new container will be started by the Docker Swarm Orchestrator.

\begin{lstlisting}[caption={Docker database service},captionpos=b,label=APIService,escapechar=\%]
%\dots%
API_PROD:                    # API service used for production
    image: giraf/web-api:1   # This will use version 1 of the API hosted on hub.docker.com
    networks:                # Attaches the network
        - frontend
        - backend
    environment:             # Sets local envionment for dotnet
        ASPNETCORE_ENVIRONMENT: Production
    deploy:                  # Deploy options
        replicas: 3          # Number of services
    volumes:                 # Mounts the two NFS file shares into the container
        - /swarm-nfs/cdn/pictograms/:/pictograms
        - /swarm-nfs/api/appsettings.Develop.json:/srv/appsettings.json
    healthcheck:             # Docker healthcheck restart of it fails three times in a row, service may be out for a maximum of 30 seconds
        test: ["CMD-SHELL", "curl --fail http://localhost:5000 || exit 1"]
        interval: 10s
        timeout: 10s
        retries: 3
%\dots%
\end{lstlisting}
